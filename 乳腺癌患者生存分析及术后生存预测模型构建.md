# **乳腺癌患者生存分析及术后生存预测模型构建**

## 0. 生存分析及模型预测相关R包导入

```R
#载入生存分析及分类预测相关R包
library(dplyr)
library(ggplot2)
library(ggpubr)
library(survminer)
library(survival)
library(survMisc)
library(moments)
library(MASS)
library(boot)
library(scatterplot3d)
library(customLayout)#拼图
library(cowplot)
library(showtext)
library(rpart)
library(tree)
library(tibble)
library(bitops)
library(rattle)
library(randomForest)
library(e1071)
library(pROC)
library(patchwork)
```

## 1. 数据预处理

```R
#载入数据
haberman_data<-read.csv("E:\\硕士阶段学业课程\\医学健康组学数据分析与挖掘\\大作业\\haberman.data")
colname_data<-c("age","year",'nodes','status')
colnames(haberman_data)<-colname_data
#数据预处理
summary(haberman)
haberman_data$status<-factor(haberman_data$status)
haberman_clear_data<-haberman_data
haberman_clear_data$status<-as.numeric(haberman_clear_data$status)
haberman_clear_data$surv_age<-ifelse(haberman_clear_data$age>=55,'old','young')
haberman_clear_data$surv_nodes<-ifelse(haberman_clear_data$nodes>=7,'many','few')
haberman_clear_data$surv_year<-70-haberman_clear_data$year
haberman_clear_data$surve_status<-ifelse(haberman_clear_data$status=='1','aliveness','death')
haberman_clear_data$surve_status<-as.factor(haberman_clear_data$surve_status)
```

## 2. 寻找变量间关系

```R
#生存状态和年龄之间关系
summary(haberman_clear_data$age)
age_summary<-group_by(haberman_clear_data,surve_status)%>%
  summarise(count=n(),mean=mean(age),median=median(age),sd=sd(age),min=min(age),var=var(age))
agedata1<-data.frame()
agedata2<-data.frame()
for (i in 1:nrow(haberman_clear_data)) {
  if (haberman_clear_data[i,8]=='aliveness'){
    agedata1<-rbind(agedata1,haberman_clear_data[i,])
  }
  else{
    agedata2<-rbind(agedata2,haberman_clear_data[i,])
  }
}
g_age<-ggplot(haberman_clear_data,aes(age))+
  geom_histogram(aes(y=..density..),stat='bin',color='black',fill='lightblue')+
  scale_y_continuous(limits = c(0,0.05),sec.axis = sec_axis(~.,breaks = c(seq(0,1,0.2))))+
  geom_density()
g_age1<-ggplot(haberman_clear_data,aes(age))+
  geom_histogram(aes(y=..density..),stat='bin',color='black',fill='lightblue')+
  facet_wrap(~haberman_clear_data$surve_status)+
  scale_y_continuous(limits = c(0,0.05),sec.axis = sec_axis(~.,breaks = c(seq(0,1,0.2))))+
  geom_density()+
  theme_set(theme_bw())
g_age_box<-ggplot(haberman_clear_data,aes(x=surve_status,y=age,fill=surve_status))+
  geom_boxplot()
#正态分布检验
shapiro.test(haberman_clear_data$age) 
shapiro.test(agedata1$age) 
shapiro.test(agedata2$age)
#偏度检测
skewness(agedata2$age)
#峰度检测
kurtosis(agedata2$age)
#秩和检验
wilcox.test(age~status, mu=0, alternative="two.sided",var.equal=F, conf.level=0.95, data = haberman_clear_data) 

#生存状态和手术时间之间的关系
summary(haberman_clear_data$year)
year_summary<-group_by(haberman_clear_data,surve_status)%>%
  summarise(count=n(),mean=mean(year),median=median(year),sd=sd(year),min=min(year),var=var(year))
g_year<-ggplot(haberman_clear_data,aes(year))+
  geom_histogram(aes(y=..density..),stat='bin',color='black',fill='lightblue',binwidth = 1)+
  geom_density()+
  theme_set(theme_bw())+
  theme(panel.grid=element_blank())
g_year1<-ggplot(haberman_clear_data,aes(year))+
  geom_histogram(aes(y=..density..),stat='bin',color='black',fill='lightblue',binwidth = 1)+
  facet_wrap(~haberman_clear_data$surve_status)+
  geom_density()+
  theme_set(theme_bw())
g_year_box<-ggplot(haberman_clear_data,aes(x=surve_status,y=year,fill=surve_status))+
  geom_boxplot()
#正态分布检验
shapiro.test(haberman_clear_data$year) 
shapiro.test(agedata1$year) 
shapiro.test(agedata2$year)
#秩和检验
wilcox.test(year~status, mu=0, alternative="two.sided",var.equal=F, conf.level=0.95, data = haberman_clear_data) 

#生存状态与结节数之间的关系
summary(haberman_clear_data$nodes)
nodes_summary<-group_by(haberman_clear_data,surve_status)%>%
  summarise(count=n(),mean=mean(nodes),median=median(nodes),sd=sd(nodes),min=min(nodes),var=var(nodes))
g_nodes<-ggplot(haberman_clear_data,aes(nodes))+
  geom_histogram(aes(y=..density..),stat='bin',color='black',fill='lightblue')+
  geom_density()+
  theme_set(theme_bw())+
  theme(panel.grid=element_blank())
g_nodes1<-ggplot(haberman_clear_data,aes(nodes))+
  geom_histogram(aes(y=..density..),stat='bin',color='black',fill='lightblue')+
  facet_wrap(~haberman_clear_data$surve_status)+
  geom_density()+
  theme_set(theme_bw())
g_nodesbox<-ggplot(haberman_clear_data,aes(x=surve_status,y=nodes,fill=surve_status))+
  geom_boxplot()
#正态分布检验
shapiro.test(haberman_clear_data$nodes) 
shapiro.test(agedata1$nodes) 
shapiro.test(agedata2$nodes)
#秩和检验
wilcox.test(nodes~status, mu=0, alternative="two.sided",var.equal=F, conf.level=0.95, data = haberman_clear_data) 

#拼图可视化单一变量分布情况
(g_age/g_age1/g_age_box)|(g_year/g_year1/g_year_box)|(g_nodes/g_nodes1/g_nodesbox)

#观察多维变量数据分布情况
age_nodes_plot<-ggplot(data = haberman_clear_data,aes(x=age,y=nodes,shape=surve_status,color=surve_status))+
  geom_point()+
  theme_light() 
age_year_plot<-ggplot(data = haberman_clear_data,aes(x=age,y=year,shape=surve_status,color=surve_status))+
  geom_point()+
  theme_light() 
year_nodes_plot<-ggplot(data = haberman_clear_data,aes(x=year,y=nodes,shape=surve_status,color=surve_status))+
  geom_point()+
  theme_light() 
colors <- c("darksalmon", "cyan")
colors <- colors[as.numeric(haberman_clear_data$status)]
scatterplot3d(haberman_clear_data[,1:3],pch = 16, color=colors,grid=TRUE, box=FALSE)
legend("right", legend=c('aliveness','death'),
       col =  c("darksalmon", "cyan"), pch = 16)
age_nodes_plot+age_year_plot+year_nodes_plot
```

## 3. 生存分析

```R
#生存分析
#创建生存对象
survobj<-with(haberman_clear_data,Surv(surv_year,status))
#kaplan-Meier生存估计
fit<-survfit(survobj~1,data=haberman_clear_data)
surv_plot<-ggsurvplot(fit,
           data = haberman_clear_data,
           conf.int = TRUE,
           risk.table = TRUE,
           surv.median.line = 'hv',
           palette = "#2E9FDF")
#不同年龄组之间的生存分析
fit1<-survfit(survobj~surv_age,data = haberman_clear_data)
summary(fit1)
survdiff(survobj~surv_age,data = haberman_clear_data)
surv_plot2<-ggsurvplot(fit1,
           data = haberman_clear_data,
           conf.int = TRUE,
           risk.table = TRUE,
           surv.median.line = 'hv',
           palette = "hue")
#不同结节组之间的生存分析
fit2<-survfit(survobj~surv_nodes,data = haberman_clear_data)
summary(fit2)
survdiff(survobj~surv_nodes,data = haberman_clear_data)
surv_plot3<-ggsurvplot(fit2,
                       data = haberman_clear_data,
                       conf.int = TRUE,
                       risk.table = TRUE,
                       surv.median.line = 'hv',
                       palette = "hue")
splots <- list()
splots[[1]] <- surv_plot
splots[[2]] <- surv_plot2
splots[[3]] <- surv_plot3
arrange_ggsurvplots(splots, print = TRUE,  
                    ncol = 3, nrow = 1)

#Cox回归
model_cox<-coxph(survobj~age+nodes,data = haberman_clear_data)
summary(model_cox)
z1<-cox.zph(model_cox)
ggcoxzph(z1)
ggforest(model_cox,data = haberman_clear_data)
```

## 4. 基于分类的乳腺癌发病模型预测

```R
#数据预处理
haberman_log_data<-haberman_data
haberman_log_data<-mutate(haberman_log_data,ifelse(haberman_data$status=='1',0,1))
haberman_log_data<-haberman_log_data[,-4]
colnames(haberman_log_data)[4]<-'status'
##交叉验证方法
set.seed(1)
train_num<-sample(305,152)
train_data<-haberman_log_data[train_num,]
test_data<-haberman_log_data[-train_num,]
```

### 4.1 Logistic回归模型

```R
#logistics回归
glm.fit<-glm(status~age+year+nodes,data = train_data,family = binomial)
summary(glm.fit)
glm.step.fit<-step(glm.fit,direction = 'both')
summary(glm.step.fit)
glm.step.probs<-predict(glm.step.fit,test_data,type='response')
glm.step.pred=rep(0,153)
glm.step.pred[glm.step.probs>0.5]=1
test_data$logistics<-glm.step.pred
t.step.glm<-table(glm.step.pred,test_data$status)
(t.step.glm[1,1]+t.step.glm[2,2])/sum(t.step.glm)#77.12%
```

### 4.2 线性判别回归模型

```R
#线性判别回归
lda.fit<-lda(status~age+year+nodes,data=train_data)
summary(lda.fit)
lda.pred<-predict(lda.fit,test_data)
test_data$lda<-lda.pred$class
t.lda<-table(lda.pred$class,test_data$status)
(t.lda[1,1]+t.lda[2,2])/sum(t.lda)
#plot(lda.fit,dimen = 1,type='both')
```

### 4.2 二次判别回归模型

```R
#二次判别回归
qda.fit<-qda(status~age+year+nodes,data = train_data)
summary(qda.fit)
qda.pred<-predict(qda.fit,test_data)
test_data$qda<-qda.pred$class
t.qda<-table(qda.pred$class,test_data$status)
(t.qda[1,1]+t.qda[2,2])/sum(t.qda)#77.78%
```

### 4.3 经典决策树模型

```R
##经典决策树方法
set.seed(123)
tree.fit<-rpart(status~.,data = train_data,method = 'class',parms = list(split='information'))
plotcp(tree.fit)
fancyRpartPlot(tree.fit,main = '决策树')
tree.fit.pred<-predict(tree.fit,test_data,type = 'class')
t.tree<-table(tree.fit.pred,test_data$status)#73.86%
(t.tree[1,1]+t.tree[2,2])/sum(t.tree)
#剪枝
tree.pruned.fit<-prune(tree.fit, cp= tree.fit$cptable[which.min(tree.fit$cptable[,"xerror"]),"CP"]) 
tree.pruned.fit$cptable
fancyRpartPlot(tree.pruned.fit,main = '决策树')
tree.pruned.fit.pred<-predict(tree.pruned.fit,test_data,type = 'class')
test_data$tree<-tree.pruned.fit.pred
t.pruned.tree<-table(tree.pruned.fit.pred,test_data$status)
(t.pruned.tree[1,1]+t.pruned.tree[2,2])/sum(t.pruned.tree)#77.78%
```

### 4.4 随机森林模型

```R
#随机森林方法
set.seed(615)
foreast.fit<-randomForest(status~.,data = train_data,na.action=na.roughfix,importance=TRUE)
importance(foreast.fit,type = 2)
foreast.pred<-predict(foreast.fit,test_data)
foreast.pred.tmp=rep(0,153)
foreast.pred.tmp[foreast.pred>0.5]=1
test_data$foreast<-foreast.pred.tmp
t.foreast<-table(foreast.pred.tmp,test_data$status)
(t.foreast[1,1]+t.foreast[2,2])/sum(t.foreast)#77.78%
```

### 4.5 支持向量机SVM模型

```R
##支持向量机方法
set.seed(123)
svm.fit<-svm(status~.,data = train_data)
svm.fit
svm.pred<-predict(svm.fit,test_data)
svm.pred.tmp=rep(0,153)
svm.pred.tmp[svm.pred>0.5]=1
test_data$svm<-svm.pred.tmp
t.svm<-table(svm.pred.tmp,test_data$status)
(t.svm[1,1]+t.svm[2,2])/sum(t.svm)#75.82%
```

### 4.6 评估不同预测模型优劣

```R
performance<-function(table,lt=list(),n=4){
  if(!all(dim(table)==c(2,2)))
    stop("Must be a 2x2 table!")
  TN=table[1,1]
  FP=table[1,2]
  FN=table[2,1]
  TP=table[2,2]
  sensitivity=TP/(TP+FN)
  specificity=TN/(TN+FP)
  PPV=TP/(TP+FP)
  NPV=TN/(TN+FN)
  hitrate=(TP+TN)/(TP+TN+FP+FN)
  result<-paste('Sensitivity = ',round(sensitivity,n),
                '\nSpecificity = ',round(specificity,n),
                '\nPositive Predictive Value = ',round(PPV,n),
                '\nNegtive Predictive Value = ',round(NPV,n),
                '\nAccuracy = ',round(hitrate,n),'\n',sep = '')
  cat(result)
  return(list(sensitivity,specificity,PPV,NPV,hitrate))
}
glm.per<-performance(t.step.glm)
qda.per<-performance(t.qda)
tree.per<-performance(t.tree)
foreast.per<-performance(t.foreast)
svm.per<-performance(t.svm)
##可视化
glm.per<-t(as.data.frame(glm.per))
qda.per<-t(as.data.frame(qda.per))
tree.per<-t(as.data.frame(tree.per))
foreast.per<-t(as.data.frame(foreast.per))
svm.per<-t(as.data.frame(svm.per))

model_per<-rbind(glm.per,qda.per)
model_per<-rbind(model_per,tree.per)
model_per<-rbind(model_per,foreast.per)
model_per<-rbind(model_per,svm.per)

indicator<-t(data.frame('sensitivity','specificity','PPV','NPV','accuracy',
   'sensitivity','specificity','PPV','NPV','accuracy',
   'sensitivity','specificity','PPV','NPV','accuracy',
   'sensitivity','specificity','PPV','NPV','accuracy',
   'sensitivity','specificity','PPV','NPV','accuracy'))
model_per<-cbind(indicator,model_per)

method<-t(data.frame('glm','glm','glm','glm','glm',
          'qda','qda','qda','qda','qda',
          'tree','tree','tree','tree','tree',
          'foreast','foreast','foreast','foreast','foreast',
          'svm','svm','svm','svm','svm'))
model_per<-cbind(method,model_per)
model_per<-as.data.frame(model_per)

rownames(model_per)<-c(1:dim(model_per)[1])
colnames(model_per)<-c('model','indicator','result')
model_per<-as.data.frame(model_per)
model_per$result<-as.numeric(model_per$result)

ggplot(model_per, aes(x=indicator, y=result, fill =model)) +
  geom_bar(stat="identity", position="dodge",colour='black') + 
  scale_fill_manual(values = c("darkgoldenrod1", "cyan1", "firebrick1",'chartreuse3','brown3','steelblue'))+
  theme_bw() 

test_data$qda<-as.numeric(as.character(test_data$qda))
test_data$tree<-as.numeric(as.character(test_data$tree))


test_data$logistic<-predict(glm.step.fit,test_data,type='response')
qda.pr<-predict(qda.fit,test_data,type='response')
test_data$qda<-qda.pr$posterior[,2]
test_data$tree<-predict(tree.fit,test_data,type = 'prob')[,2]
test_data$foreast<-predict(foreast.fit,test_data,type = 'response')
test_data$svm<-predict(svm.fit,test_data,type = 'response')
##ROC曲线的绘制
ROC_logistics<-roc(test_data$status,test_data$logistic)
ROC_qda<-roc(test_data$status,test_data$qda)
ROC_tree<-roc(test_data$status,test_data$tree)
ROC_foreast<-roc(test_data$status,test_data$foreast)
ROC_svm<-roc(test_data$status,test_data$svm)
round(ci(auc(ROC_logistics)),3)
round(ci(auc(ROC_qda)),3)
round(ci(auc(ROC_tree)),3)
round(ci(auc(ROC_foreast)),3)
round(ci(auc(ROC_svm)),3)
plot(1-ROC_logistics$specificities,ROC_logistics$sensitivities,type = 'l',col='darkgoldenrod1',lty=1,xlab = 'Specificity',ylab = 'Sensitivity',lwd=2.5)
lines(1-ROC_qda$specificities,ROC_qda$sensitivities,type = 'l',col='cyan1',lty=1,lwd=2.5)
lines(1-ROC_tree$specificities,ROC_tree$sensitivities,type = 'l',col='firebrick1',lty=1,lwd=2.5)
lines(1-ROC_foreast$specificities,ROC_foreast$sensitivities,type = 'l',col='chartreuse3',lty=1,lwd=2.5)
lines(1-ROC_svm$specificities,ROC_svm$sensitivities,type = 'l',col='brown3',lty=1,lwd=2.5)
abline(0,1)
legend(0.6,0.35,
       c('logistics 0.687 [0.581,0.793]','qda 0.705 [0.602 0.809]','tree  0.684 [0.587 0.781]','foreast 0.717 [0.620 0.813]','svm 0.753 [0.662 0.843]'),
       lty = c(2,2,2,2,2),
       lwd = c(5,5,5,5,5),
       col = c("darkgoldenrod1", "cyan1", "firebrick1",'chartreuse3','brown3','steelblue'),
       bty = 'n'
)
legend(0.8,0.38,'AUC',bty='n')
```

